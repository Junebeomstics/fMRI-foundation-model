{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56bbd92-27d1-4f94-a579-029661eb72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import boto3\n",
    "import webdataset as wds\n",
    "import nibabel as nib\n",
    "import pickle as pkl\n",
    "from einops import rearrange\n",
    "from subprocess import call\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchio as tio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2311d566-6ece-481e-b86b-e768def16f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reshape_to_2d(tensor):\n",
    "    return rearrange(tensor, 'b h w c -> (b h) (c w)')\n",
    "\n",
    "def reshape_to_original(tensor_2d, b=300, h=64, w=64, c=48):\n",
    "    return rearrange(tensor_2d, '(b h) (c w) -> b h w c', b=b, h=h, w=w, c=c)\n",
    "\n",
    "def header_to_dict(header):\n",
    "    header=func_nii.header\n",
    "    readable_header = {}\n",
    "    for key, value in header.items():\n",
    "        readable_header[key] = value\n",
    "    return readable_header\n",
    "\n",
    "def temporal_interp1d(fmri_data, change_TR):\n",
    "    original_time_points = np.arange(fmri_data.shape[0])  # Time points: 0, 1, 2, ..., T-1\n",
    "    new_time_points = np.arange(0, fmri_data.shape[0], change_TR)  # New time points: 0, 2, 4, ...\n",
    "\n",
    "    reshaped_data = fmri_data.reshape(fmri_data.shape[0], -1)  # Reshape to (T, X*Y*Z)\n",
    "    interpolate = interp1d(original_time_points, reshaped_data, kind='linear', axis=0, bounds_error=False, fill_value=\"extrapolate\")\n",
    "    resampled_fmri_data = interpolate(new_time_points).reshape((len(new_time_points),) + fmri_data.shape[1:])\n",
    "    return resampled_fmri_data\n",
    "\n",
    "def list_folders(bucket, prefix='', delimiter='/'):\n",
    "    folder_names = []\n",
    "    continuation_token = None\n",
    "    while True:\n",
    "        # Include the continuation token in the request if it exists\n",
    "        kwargs = {'Bucket': bucket, 'Prefix': prefix, 'Delimiter': delimiter}\n",
    "        if continuation_token:\n",
    "            kwargs['ContinuationToken'] = continuation_token\n",
    "\n",
    "        response = s3.list_objects_v2(**kwargs)\n",
    "        folder_names.extend([x['Prefix'].split('/')[-2] for x in response.get('CommonPrefixes', [])])\n",
    "\n",
    "        # Check if more items are available to retrieve\n",
    "        if 'NextContinuationToken' in response:\n",
    "            continuation_token = response['NextContinuationToken']\n",
    "        else:\n",
    "            break\n",
    "    return folder_names\n",
    "\n",
    "def list_all_objects(bucket, prefix):\n",
    "    continuation_token = None\n",
    "    while True:\n",
    "        if continuation_token:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix, ContinuationToken=continuation_token)\n",
    "        else:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "        for content in response.get('Contents', []):\n",
    "            yield content\n",
    "\n",
    "        continuation_token = response.get('NextContinuationToken')\n",
    "        if not continuation_token:\n",
    "            break\n",
    "\n",
    "def torchio_slice(data,xslice=None,yslice=None,zslice=None):    \n",
    "    if xslice is None: xslice = data.shape[1] // 2\n",
    "    if yslice is None: yslice = data.shape[2] // 2\n",
    "    if zslice is None: zslice = data.shape[3] // 2\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(5,5))\n",
    "\n",
    "    # Plot the three different slices\n",
    "    axs[0].imshow(data[0, xslice], cmap='gray')\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title(f'Slice [0, {xslice}]', fontsize=8)\n",
    "\n",
    "    axs[1].imshow(data[0, :, yslice], cmap='gray')\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title(f'Slice [0, :, {yslice}]', fontsize=8)\n",
    "\n",
    "    axs[2].imshow(data[0, :, :, zslice], cmap='gray')\n",
    "    axs[2].axis('off')\n",
    "    axs[2].set_title(f'Slice [0, :, :, {zslice}]', fontsize=8)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, '__file__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3203b80a-b858-4e67-ab06-b06fa01aeca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_name = \"openneuro\"\n",
    "outpath=f\"/scratch/{proj_name}\"\n",
    "os.makedirs(os.path.dirname(outpath), exist_ok=True)\n",
    "os.makedirs(f\"{outpath}/tars\", exist_ok=True)\n",
    "\n",
    "# Below code assumes you are resuming your data creation from killed job ##\n",
    "\n",
    "# copy metadata.json from s3 to /scratch\n",
    "command = f\"aws s3 cp s3://proj-fmri/fmri_foundation_datasets/{proj_name}/metadata.json {outpath}/tars/metadata.json --region us-west-2\"\n",
    "call(command,shell=True)\n",
    "\n",
    "# read the metadata file\n",
    "with open(f\"{outpath}/tars/metadata.json\", 'r') as file:\n",
    "    metadata = json.load(file)\n",
    "    \n",
    "TR_count = metadata['TR_count']\n",
    "subj_count = metadata['subj_count']\n",
    "tar_count = metadata['tar_count'] + 1\n",
    "dataset_count = metadata['dataset_count']\n",
    "obj_key_list = metadata['obj_key_list']\n",
    "dataset_list = metadata['datasets']\n",
    "\n",
    "# delete existing tars\n",
    "command = f\"rm {outpath}/tars/*.tar\"\n",
    "call(command,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7390b30-c143-4f92-ab60-82595eea681a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_DATASETS: 1015 TRs_per_sample: 24 max_samples_per_tar: 320 max_TRs_per_tar: 7680\n"
     ]
    }
   ],
   "source": [
    "TRs_per_sample = 24\n",
    "max_samples_per_tar = 320 # translates to around 1 Gb per tar\n",
    "max_TRs_per_tar = max_samples_per_tar * TRs_per_sample\n",
    "\n",
    "# Connect to S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Set the bucket name and folder name\n",
    "bucket_name = 'openneuro.org'\n",
    "folder_names = list_folders(bucket_name)\n",
    "NUM_DATASETS = len(folder_names)\n",
    "\n",
    "print(f\"NUM_DATASETS: {NUM_DATASETS} TRs_per_sample: {TRs_per_sample} \\\n",
    "max_samples_per_tar: {max_samples_per_tar} max_TRs_per_tar: {max_TRs_per_tar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6d9789-dc4f-445a-b19f-927ee58fd1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # If you want to start over webdataset creation from the beginning, uncomment these:\n",
    "# tar_count = 0\n",
    "# TR_count = 0\n",
    "# subj_count = 0\n",
    "# dataset_count = 0\n",
    "# dataset_list = []\n",
    "# obj_key_list = []\n",
    "\n",
    "sample_idx = 0\n",
    "current_dataset = None\n",
    "current_subject = None\n",
    "sink = wds.TarWriter(f\"{outpath}/tars/{tar_count:06d}.tar\")\n",
    "\n",
    "tio_transforms = tio.Compose(\n",
    "                (\n",
    "                    tio.ToCanonical(), # make sure orientation of brains are consistent (RAS+ orientation)\n",
    "                    tio.RescaleIntensity(out_min_max=(0, 1)),\n",
    "                    tio.Resample(3, image_interpolation='nearest'), # rescale voxels to #mm isotropic\n",
    "                    tio.CropOrPad((64, 64, 48)),\n",
    "                )\n",
    "            )\n",
    "# tio_image = tio.ScalarImage(filename, dtype=np.float32)\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    # List all objects in the folder\n",
    "    all_objects = list_all_objects(bucket_name, folder_name)\n",
    "    for obj in all_objects:\n",
    "        obj_key = obj['Key']\n",
    "        \n",
    "#         if '_T1w.nii.gz' in obj_key: # Anatomical\n",
    "#             # Store subject number to verify anat/func match\n",
    "#             anat_subj = obj_key.split('/')[1]\n",
    "            \n",
    "#             # Download the object to tmp location\n",
    "#             filename = os.path.join('openneuro', obj_key)\n",
    "#             os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "#             s3.download_file(bucket_name, obj_key, filename)\n",
    "\n",
    "#             # store the header of anat\n",
    "#             anat_header = nib.load(filename).header\n",
    "            \n",
    "        if '_bold.nii.gz' in obj_key:\n",
    "            func_subj = obj_key.split('/')[1]\n",
    "            \n",
    "            # Verify func/anat subject number match\n",
    "            # if anat_subj != func_subj:\n",
    "            #     print('Incompatible subject number found. Skipping...')\n",
    "            #     continue\n",
    "                \n",
    "            # if metadata file shows you already processed this file, skip it\n",
    "            if np.isin(obj_key, obj_key_list):\n",
    "                continue\n",
    "            \n",
    "            filename = os.path.join(f'{os.getcwd()}/openneuro', obj_key)\n",
    "            \n",
    "            os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "            if not os.path.exists(filename):\n",
    "                s3.download_file(bucket_name, obj_key, filename)\n",
    "\n",
    "            func_nii = nib.load(filename)\n",
    "            try:\n",
    "                print(obj_key, func_nii.get_fdata().shape, \"| TRs:\", TR_count, \"samp:\", sample_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"get_fdata() error occurred: {e}\")\n",
    "                continue \n",
    "            \n",
    "            try:\n",
    "                tio_image = tio.ScalarImage(tensor=np.moveaxis(func_nii.get_fdata(),-1,0).astype(np.float32), \n",
    "                                        affine=func_nii.affine, \n",
    "                                        dtype=np.float32)\n",
    "                out = tio_transforms(tio_image)['data']            \n",
    "            except Exception as e: # this can happen if the func is actually 3d and not 4d\n",
    "                print(f\"tio processing error occurred: {e}\")\n",
    "                continue \n",
    "                \n",
    "            # # discard datasets with unusual Repetition Time\n",
    "            # orig_TR = func_nii.header.get_zooms()[3]\n",
    "            # if orig_TR > 100: # assuming it is in milliseconds\n",
    "            #     orig_TR = orig_TR / 1000\n",
    "            # if orig_TR < 1 or orig_TR > 3:\n",
    "            #     print(f\"skipped due to orig_TR = {orig_TR}\")\n",
    "            #     continue\n",
    "                \n",
    "            # zscore across the run\n",
    "            out_shape = out.shape\n",
    "            out = out.reshape(len(out),-1)\n",
    "            scalar = StandardScaler(with_mean=True, with_std=True).fit(out)\n",
    "            mean = scalar.mean_\n",
    "            sd = scalar.scale_\n",
    "            out = (out - mean) / sd\n",
    "            mean = mean.reshape([out_shape[1],out_shape[2],out_shape[3]])\n",
    "            sd = sd.reshape([out_shape[1],out_shape[2],out_shape[3]])\n",
    "            meansd = np.array([mean,sd])\n",
    "            out = out.reshape(out_shape)\n",
    "            \n",
    "            # create 16-bit png of mean and sd volumes\n",
    "            meansd_images = reshape_to_2d(meansd)\n",
    "            meansd_images = torch.Tensor(meansd_images)\n",
    "            min_meansd, max_meansd = meansd_images.min(), meansd_images.max() \n",
    "            minmax_meansd_images = (meansd_images - min_meansd) / (max_meansd - min_meansd) # first you need to rescale to 0 to 1\n",
    "            rescaled_images = (minmax_meansd_images * 65535).to(torch.int16) # then multiply by constant prior to numpy uint16\n",
    "            rescaled_images_numpy = rescaled_images.numpy().astype(np.uint16)\n",
    "            meansd_PIL_image = Image.fromarray(rescaled_images_numpy, mode='I;16')\n",
    "\n",
    "            # create samples of TRs_per_sample TRs\n",
    "            for batch in range(0,len(out),TRs_per_sample):\n",
    "                if len(out[batch:batch+TRs_per_sample])<TRs_per_sample: continue\n",
    "                images = reshape_to_2d(out[batch:batch+TRs_per_sample])\n",
    "                images = torch.Tensor(images)\n",
    "\n",
    "                # convert tensor to something compatible with 16-bit png\n",
    "                min_, max_ = images.min(), images.max()\n",
    "                minmax_images = (images - min_) / (max_ - min_) # first you need to rescale to 0 to 1\n",
    "                rescaled_images = (minmax_images * 65535).to(torch.int16) # then multiply by constant prior to numpy uint16\n",
    "                rescaled_images_numpy = rescaled_images.numpy().astype(np.uint16)\n",
    "                PIL_image = Image.fromarray(rescaled_images_numpy, mode='I;16')\n",
    "\n",
    "                if current_dataset != obj['Key'].split('/')[0]:\n",
    "                    print(obj_key, \"| TR_count:\", TR_count, \"sample_idx:\", sample_idx)\n",
    "                    dataset_list.append(obj['Key'].split('/')[0])\n",
    "                    dataset_count += 1\n",
    "                    if is_interactive(): # dont want to plot unless you are in interactive notebook\n",
    "                        torchio_slice(out) # plot normalized slices\n",
    "                        torchio_slice((out * sd) + mean) # plot unnormalized slices\n",
    "\n",
    "                if current_subject != obj['Key'].split('/')[1]: \n",
    "                    subj_count += 1\n",
    "                current_dataset = obj['Key'].split('/')[0]  \n",
    "                current_subject = obj['Key'].split('/')[1]  \n",
    "\n",
    "                sink.write({\n",
    "                    \"__key__\": \"%06d\" % sample_idx,\n",
    "                    \"dataset.txt\": obj_key,\n",
    "                    \"header.npy\": np.array(header_to_dict(func_nii.header)),\n",
    "                    \"minmax.npy\": np.array([min_, max_, min_meansd, max_meansd]),\n",
    "                    \"meansd.png\": meansd_PIL_image,\n",
    "                    \"func.png\": PIL_image, # 27M for 8-bit png vs 48M for 16-bit png vs 144M for numpy\n",
    "                })\n",
    "                TR_count += TRs_per_sample\n",
    "                sample_idx += 1\n",
    "\n",
    "                if sample_idx >= max_samples_per_tar:\n",
    "                    print(\"HIT MAX SAMPLES PER TAR\")\n",
    "                    sink.close()\n",
    "                    sample_idx = 0\n",
    "\n",
    "                    # make metadata file and save progress to aws s3\n",
    "                    data = {\n",
    "                        \"TR_count\": TR_count,\n",
    "                        \"subj_count\": subj_count,\n",
    "                        \"tar_count\": tar_count,\n",
    "                        \"dataset_count\": dataset_count,\n",
    "                        \"datasets\": dataset_list,\n",
    "                        \"obj_key_list\": obj_key_list,\n",
    "                    }\n",
    "                    with open(f\"{outpath}/tars/metadata.json\", \"w\") as file:\n",
    "                        json.dump(data, file)\n",
    "\n",
    "                    # send to aws s3\n",
    "                    command = f\"aws s3 sync {outpath}/tars s3://proj-fmri/fmri_foundation_datasets/{proj_name} --region us-west-2\"\n",
    "                    call(command,shell=True)\n",
    "\n",
    "                    # delete tars\n",
    "                    command = f\"rm {outpath}/tars/*.tar\"\n",
    "                    call(command,shell=True)\n",
    "\n",
    "                    tar_count += 1\n",
    "                    sink = wds.TarWriter(f\"{outpath}/tars/{tar_count:06d}.tar\")\n",
    "                    \n",
    "            obj_key_list.append(obj['Key'])\n",
    "\n",
    "            # delete the nifti now that youve saved it to numpy\n",
    "            call(f\"rm {filename}\",shell=True) \n",
    "\n",
    "print(\"TR_count\",TR_count)\n",
    "print(\"subj_count\",subj_count)\n",
    "print(\"dataset_count\",dataset_count)\n",
    "print(\"tar_count\", tar_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894bc6b-298c-48d4-a1bc-1bcbb4c3ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sink.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "data = {\n",
    "    \"TR_count\": TR_count,\n",
    "    \"subj_count\": subj_count,\n",
    "    \"tar_count\": tar_count,\n",
    "    \"dataset_count\": dataset_count,\n",
    "    \"datasets\": dataset_list,\n",
    "    \"obj_key_list\": obj_key_list,\n",
    "}\n",
    "print(data)\n",
    "\n",
    "with open(f\"{outpath}/tars/metadata.json\", \"w\") as file:\n",
    "    json.dump(data, file)\n",
    "    \n",
    "# send to aws s3\n",
    "command = f\"aws s3 sync {outpath}/tars s3://proj-fmri/fmri_foundation_datasets/{proj_name} --region us-west-2\"\n",
    "call(command,shell=True)\n",
    "\n",
    "# delete tars\n",
    "command = f\"rm {outpath}/tars/*.tar\"\n",
    "call(command,shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
